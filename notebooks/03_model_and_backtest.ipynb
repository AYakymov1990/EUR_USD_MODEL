{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5c3451ef",
      "metadata": {},
      "source": [
        "# 03 — Модель и бэктест (валидация + диагностика)\n",
        "\n",
        "Порог и полярность подбираются только на ВАЛИДАЦИИ, тест — финальная честная оценка.\n",
        "Диагностика trade_count и экспозиции помогает понять, почему сделок мало."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ffa0d27",
      "metadata": {},
      "source": [
        "Полярность (pred vs -pred) рассматриваем как гиперпараметр,\n",
        "поэтому выбираем её на валидации. Порог также фиксируется по валидации.\n",
        "Это защищает от утечки информации из теста."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7411312c",
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'src'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeatures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_feature_columns, drop_na_for_training\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrainConfig, StandardScaler, train_mlp_model, predict, compute_regression_metrics\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbacktest\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backtest_long_short, backtest_long_short_horizon\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "PROJECT_ROOT = Path.cwd().resolve()\n",
        "if (PROJECT_ROOT / \"src\").exists():\n",
        "    ROOT = PROJECT_ROOT\n",
        "elif (PROJECT_ROOT.parent / \"src\").exists():\n",
        "    ROOT = PROJECT_ROOT.parent\n",
        "else:\n",
        "    ROOT = PROJECT_ROOT\n",
        "\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT))\n",
        "\n",
        "from src.features import get_feature_columns, drop_na_for_training\n",
        "from src.model import TrainConfig, StandardScaler, train_mlp_model, predict, compute_regression_metrics\n",
        "from src.backtest import backtest_long_short, backtest_long_short_horizon\n",
        "\n",
        "DATA_PATH = ROOT / \"data\" / \"eurusd_features.parquet\"\n",
        "ARTIFACT_DIR = ROOT / \"data\" / \"artifacts\"\n",
        "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "df = pd.read_parquet(DATA_PATH)\n",
        "df = drop_na_for_training(df)\n",
        "df = df.sort_values(\"time\").reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f2d36b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_cols = get_feature_columns()\n",
        "X = df[feature_cols].values\n",
        "y = df[\"target\"].values\n",
        "\n",
        "assert np.isfinite(X).all(), \"NaNs or infs in features\"\n",
        "assert df[\"time\"].is_monotonic_increasing, \"Time must be sorted\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "318f2717",
      "metadata": {},
      "outputs": [],
      "source": [
        "n = len(df)\n",
        "train_end = int(n * 0.70)\n",
        "val_end = int(n * 0.85)\n",
        "\n",
        "X_train, y_train = X[:train_end], y[:train_end]\n",
        "X_val, y_val = X[train_end:val_end], y[train_end:val_end]\n",
        "X_test, y_test = X[val_end:], y[val_end:]\n",
        "\n",
        "df_val = df.iloc[train_end:val_end].reset_index(drop=True)\n",
        "df_test = df.iloc[val_end:].reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c75f9083",
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_val_s = scaler.transform(X_val)\n",
        "X_test_s = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68da4fb0",
      "metadata": {},
      "outputs": [],
      "source": [
        "cfg = TrainConfig(epochs=200, batch_size=1024, lr=1e-3, weight_decay=1e-4, patience=5)\n",
        "model, history = train_mlp_model(X_train_s, y_train, X_val_s, y_val, cfg)\n",
        "\n",
        "pred_val = predict(model, X_val_s)\n",
        "pred_test = predict(model, X_test_s)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87c97140",
      "metadata": {},
      "outputs": [],
      "source": [
        "bt_pos = backtest_long_short_horizon(df_val.assign(pred=pred_val), threshold=0.0, hold_bars=3)\n",
        "bt_neg = backtest_long_short_horizon(df_val.assign(pred=-pred_val), threshold=0.0, hold_bars=3)\n",
        "\n",
        "polarity = 1 if bt_pos.metrics[\"sharpe\"] >= bt_neg.metrics[\"sharpe\"] else -1\n",
        "print(\"VAL Sharpe pos:\", bt_pos.metrics[\"sharpe\"], \"neg:\", bt_neg.metrics[\"sharpe\"])\n",
        "print(\"Chosen polarity:\", polarity)\n",
        "\n",
        "pred_val_final = polarity * pred_val\n",
        "pred_test_final = polarity * pred_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bc57008",
      "metadata": {},
      "outputs": [],
      "source": [
        "abs_pred = np.abs(pred_val_final)\n",
        "quantiles = [0.50, 0.60, 0.70, 0.80, 0.90, 0.95]\n",
        "thresholds = sorted(set([float(np.quantile(abs_pred, q)) for q in quantiles]))\n",
        "\n",
        "regimes = [None, \"adx\", \"h1_align\", \"adx_and_h1\"]\n",
        "\n",
        "val_rows = []\n",
        "for th in thresholds:\n",
        "    for reg in regimes:\n",
        "        bt = backtest_long_short_horizon(\n",
        "            df_val.assign(pred=pred_val_final),\n",
        "            threshold=th,\n",
        "            hold_bars=3,\n",
        "            cost_bps=0.5,\n",
        "            regime=reg,\n",
        "        )\n",
        "        m = bt.metrics\n",
        "        d = bt.debug\n",
        "        val_rows.append(\n",
        "            {\n",
        "                \"threshold\": th,\n",
        "                \"regime\": reg,\n",
        "                \"sharpe\": m[\"sharpe\"],\n",
        "                \"total_return\": m[\"total_return\"],\n",
        "                \"max_drawdown\": m[\"max_drawdown\"],\n",
        "                \"trade_count\": m[\"trade_count\"],\n",
        "                \"signal_counts\": d[\"signal_counts\"],\n",
        "            }\n",
        "        )\n",
        "\n",
        "val_table = pd.DataFrame(val_rows)\n",
        "val_table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "addecb16",
      "metadata": {},
      "outputs": [],
      "source": [
        "valid = val_table[val_table[\"trade_count\"] >= 20]\n",
        "if len(valid) == 0:\n",
        "    print(\"WARNING: No valid thresholds with trade_count >= 20; using first row\")\n",
        "    best_row = val_table.iloc[0]\n",
        "else:\n",
        "    valid = valid.sort_values([\"sharpe\", \"max_drawdown\", \"total_return\"], ascending=[False, False, False])\n",
        "    best_row = valid.iloc[0]\n",
        "\n",
        "best_threshold = float(best_row[\"threshold\"])\n",
        "best_regime = best_row[\"regime\"]\n",
        "print(\"Selected (VAL):\", best_threshold, best_regime)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9271adf5",
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics_val = compute_regression_metrics(pred_val_final, y_val)\n",
        "metrics_test = compute_regression_metrics(pred_test_final, y_test)\n",
        "\n",
        "bt_test = backtest_long_short_horizon(\n",
        "    df_test.assign(pred=pred_test_final),\n",
        "    threshold=best_threshold,\n",
        "    hold_bars=3,\n",
        "    cost_bps=0.5,\n",
        "    regime=best_regime,\n",
        ")\n",
        "\n",
        "print(\"VAL metrics:\", metrics_val)\n",
        "print(\"TEST metrics:\", metrics_test)\n",
        "print(\"TEST backtest metrics:\", bt_test.metrics)\n",
        "print(\"TEST debug:\", bt_test.debug)\n",
        "\n",
        "bt_test.trades.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9e79fd9",
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_bt = backtest_long_short(df_test.assign(pred=0.0), threshold=0.0)\n",
        "print(\"Baseline pred=0 metrics:\", baseline_bt.metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29ff3989",
      "metadata": {},
      "source": [
        "Печатаем критерии остановки и возможные причины провала.\n",
        "Если trade_count низкий, вероятно порог слишком высокий или предсказания почти нулевые."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "750b8ed4",
      "metadata": {},
      "outputs": [],
      "source": [
        "criteria = {\n",
        "    \"sharpe_ok\": bt_test.metrics[\"sharpe\"] >= 0.30,\n",
        "    \"maxdd_ok\": bt_test.metrics[\"max_drawdown\"] >= -0.12,\n",
        "    \"trades_ok\": bt_test.metrics[\"trade_count\"] >= 20,\n",
        "    \"diracc_ok\": metrics_test[\"dir_acc\"] >= 0.51,\n",
        "}\n",
        "print(\"PASS/FAIL:\", criteria)\n",
        "\n",
        "if not all(criteria.values()):\n",
        "    print(\"Likely causes:\")\n",
        "    if bt_test.metrics[\"trade_count\"] < 20:\n",
        "        print(\"1) Too few trades: threshold too high or predictions near zero.\")\n",
        "    if bt_test.debug.get(\"pred_abs_p95\", 0) < best_threshold:\n",
        "        print(\"2) Threshold above prediction scale; decrease quantiles.\")\n",
        "    if bt_test.debug.get(\"signal_counts\", {}).get(\"long\", 0) == 0 or bt_test.debug.get(\"signal_counts\", {}).get(\"short\", 0) == 0:\n",
        "        print(\"3) Model predicts mostly one sign; consider polarity or regularization.\")\n",
        "\n",
        "results_payload = {\n",
        "    \"polarity\": polarity,\n",
        "    \"threshold\": best_threshold,\n",
        "    \"regime\": best_regime,\n",
        "    \"val_metrics\": metrics_val,\n",
        "    \"test_metrics\": metrics_test,\n",
        "    \"test_backtest_metrics\": bt_test.metrics,\n",
        "}\n",
        "with (ARTIFACT_DIR / \"results.json\").open(\"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(results_payload, f, ensure_ascii=False, indent=2)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
